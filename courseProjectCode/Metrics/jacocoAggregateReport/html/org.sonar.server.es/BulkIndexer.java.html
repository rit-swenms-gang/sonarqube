<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>BulkIndexer.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">sonarqube</a> &gt; <a href="index.source.html" class="el_package">org.sonar.server.es</a> &gt; <span class="el_source">BulkIndexer.java</span></div><h1>BulkIndexer.java</h1><pre class="source lang-java linenums">/*
 * SonarQube
 * Copyright (C) 2009-2025 SonarSource SA
 * mailto:info AT sonarsource DOT com
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 3 of the License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with this program; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 */
package org.sonar.server.es;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.LinkedHashMultiset;
import com.google.common.collect.Multiset;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;
import javax.annotation.Nullable;
import org.elasticsearch.action.DocWriteRequest;
import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeRequest;
import org.elasticsearch.action.admin.indices.settings.get.GetSettingsRequest;
import org.elasticsearch.action.admin.indices.settings.get.GetSettingsResponse;
import org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsRequest;
import org.elasticsearch.action.bulk.BackoffPolicy;
import org.elasticsearch.action.bulk.BulkItemResponse;
import org.elasticsearch.action.bulk.BulkProcessor;
import org.elasticsearch.action.bulk.BulkProcessor.Listener;
import org.elasticsearch.action.bulk.BulkRequest;
import org.elasticsearch.action.bulk.BulkResponse;
import org.elasticsearch.action.delete.DeleteRequest;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.search.ClearScrollRequest;
import org.elasticsearch.action.search.SearchRequest;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.action.search.SearchScrollRequest;
import org.elasticsearch.action.update.UpdateRequest;
import org.elasticsearch.cluster.metadata.IndexMetadata;
import org.elasticsearch.common.document.DocumentField;
import org.elasticsearch.common.unit.ByteSizeUnit;
import org.elasticsearch.common.unit.ByteSizeValue;
import org.elasticsearch.core.TimeValue;
import org.elasticsearch.search.SearchHit;
import org.elasticsearch.search.sort.SortOrder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.sonar.api.utils.log.Profiler;
import org.sonar.core.util.ProgressLogger;

import static java.lang.String.format;

/**
 * Helper to bulk requests in an efficient way :
 * &lt;ul&gt;
 * &lt;li&gt;bulk request is sent on the wire when its size is higher than 5Mb&lt;/li&gt;
 * &lt;li&gt;on large table indexing, replicas and automatic refresh can be temporarily disabled&lt;/li&gt;
 * &lt;/ul&gt;
 */
public class BulkIndexer {

<span class="fc" id="L75">  private static final Logger LOGGER = LoggerFactory.getLogger(BulkIndexer.class);</span>
<span class="fc" id="L76">  private static final ByteSizeValue FLUSH_BYTE_SIZE = new ByteSizeValue(1, ByteSizeUnit.MB);</span>
  private static final int FLUSH_ACTIONS = -1;
  private static final String REFRESH_INTERVAL_SETTING = &quot;index.refresh_interval&quot;;
  private static final int DEFAULT_NUMBER_OF_SHARDS = 5;

  private final EsClient esClient;

  private final IndexType indexType;
  private final BulkProcessor bulkProcessor;
<span class="fc" id="L85">  private final IndexingResult result = new IndexingResult();</span>
  private final IndexingListener indexingListener;
  private final SizeHandler sizeHandler;

  public BulkIndexer(EsClient client, IndexType indexType, Size size) {
<span class="fc" id="L90">    this(client, indexType, size, IndexingListener.FAIL_ON_ERROR);</span>
<span class="fc" id="L91">  }</span>

<span class="fc" id="L93">  public BulkIndexer(EsClient client, IndexType indexType, Size size, IndexingListener indexingListener) {</span>
<span class="fc" id="L94">    this.esClient = client;</span>
<span class="fc" id="L95">    this.indexType = indexType;</span>
<span class="fc" id="L96">    this.sizeHandler = size.createHandler(Runtime2.INSTANCE);</span>
<span class="fc" id="L97">    this.indexingListener = indexingListener;</span>
<span class="fc" id="L98">    BulkProcessorListener bulkProcessorListener = new BulkProcessorListener();</span>
<span class="fc" id="L99">    this.bulkProcessor = BulkProcessor.builder(</span>
<span class="fc" id="L100">      client::bulkAsync,</span>
      bulkProcessorListener)
<span class="fc" id="L102">      .setBackoffPolicy(BackoffPolicy.exponentialBackoff())</span>
<span class="fc" id="L103">      .setBulkSize(FLUSH_BYTE_SIZE)</span>
<span class="fc" id="L104">      .setBulkActions(FLUSH_ACTIONS)</span>
<span class="fc" id="L105">      .setConcurrentRequests(sizeHandler.getConcurrentRequests())</span>
<span class="fc" id="L106">      .build();</span>
<span class="fc" id="L107">  }</span>

  public IndexType getIndexType() {
<span class="fc" id="L110">    return indexType;</span>
  }

  public void start() {
<span class="fc" id="L114">    result.clear();</span>
<span class="fc" id="L115">    sizeHandler.beforeStart(this);</span>
<span class="fc" id="L116">  }</span>

  /**
   * @return the number of documents successfully indexed
   */
  public IndexingResult stop() {
    try {
<span class="fc" id="L123">      bulkProcessor.awaitClose(1, TimeUnit.MINUTES);</span>
<span class="nc" id="L124">    } catch (InterruptedException e) {</span>
<span class="nc" id="L125">      Thread.currentThread().interrupt();</span>
<span class="nc" id="L126">      throw new IllegalStateException(&quot;Elasticsearch bulk requests still being executed after 1 minute&quot;, e);</span>
<span class="fc" id="L127">    }</span>

<span class="fc" id="L129">    esClient.refresh(indexType.getMainType().getIndex());</span>

<span class="fc" id="L131">    sizeHandler.afterStop(this);</span>
<span class="fc" id="L132">    indexingListener.onFinish(result);</span>
<span class="fc" id="L133">    return result;</span>
  }

  public void add(IndexRequest request) {
<span class="fc" id="L137">    result.incrementRequests();</span>
<span class="fc" id="L138">    bulkProcessor.add(request);</span>
<span class="fc" id="L139">  }</span>

  public void add(DeleteRequest request) {
<span class="fc" id="L142">    result.incrementRequests();</span>
<span class="fc" id="L143">    bulkProcessor.add(request);</span>
<span class="fc" id="L144">  }</span>

  public void add(DocWriteRequest request) {
<span class="nc" id="L147">    result.incrementRequests();</span>
<span class="nc" id="L148">    bulkProcessor.add(request);</span>
<span class="nc" id="L149">  }</span>

  public void addDeletion(SearchRequest searchRequest) {
    // TODO to be replaced by delete_by_query that is back in ES5
<span class="fc" id="L153">    searchRequest</span>
<span class="fc" id="L154">      .scroll(TimeValue.timeValueMinutes(5))</span>
<span class="fc" id="L155">      .source()</span>
<span class="fc" id="L156">      .sort(&quot;_doc&quot;, SortOrder.ASC)</span>
<span class="fc" id="L157">      .size(100)</span>
      // load only doc ids, not _source fields
<span class="fc" id="L159">      .fetchSource(false);</span>

    // this search is synchronous. An optimization would be to be non-blocking,
    // but it requires to tracking pending requests in close().
    // Same semaphore can't be reused because of potential deadlock (requires to acquire
    // two locks)
<span class="fc" id="L165">    SearchResponse searchResponse = esClient.search(searchRequest);</span>

    while (true) {
<span class="fc" id="L168">      SearchHit[] hits = searchResponse.getHits().getHits();</span>
<span class="fc bfc" id="L169" title="All 2 branches covered.">      for (SearchHit hit : hits) {</span>
<span class="fc" id="L170">        DocumentField routing = hit.field(&quot;_routing&quot;);</span>
<span class="fc" id="L171">        DeleteRequest deleteRequest = new DeleteRequest(hit.getIndex(), hit.getType(), hit.getId());</span>
<span class="fc bfc" id="L172" title="All 2 branches covered.">        if (routing != null) {</span>
<span class="fc" id="L173">          deleteRequest.routing(routing.getValue());</span>
        }
<span class="fc" id="L175">        add(deleteRequest);</span>
      }

<span class="fc" id="L178">      String scrollId = searchResponse.getScrollId();</span>
<span class="pc bpc" id="L179" title="1 of 2 branches missed.">      if (scrollId == null) {</span>
<span class="nc" id="L180">        break;</span>
      }
<span class="fc" id="L182">      searchResponse = esClient.scroll(new SearchScrollRequest(scrollId).scroll(TimeValue.timeValueMinutes(5)));</span>
<span class="fc bfc" id="L183" title="All 2 branches covered.">      if (hits.length == 0) {</span>
<span class="fc" id="L184">        ClearScrollRequest clearScrollRequest = new ClearScrollRequest();</span>
<span class="fc" id="L185">        clearScrollRequest.addScrollId(scrollId);</span>
<span class="fc" id="L186">        esClient.clearScroll(clearScrollRequest);</span>
<span class="fc" id="L187">        break;</span>
      }
<span class="fc" id="L189">    }</span>
<span class="fc" id="L190">  }</span>

  public void addDeletion(IndexType indexType, String id) {
<span class="fc" id="L193">    add(new DeleteRequest(indexType.getMainType().getIndex().getName())</span>
<span class="fc" id="L194">      .id(id));</span>
<span class="fc" id="L195">  }</span>

  public void addDeletion(IndexType indexType, String id, @Nullable String routing) {
<span class="fc" id="L198">    add(new DeleteRequest(indexType.getMainType().getIndex().getName())</span>
<span class="fc" id="L199">      .id(id)</span>
<span class="fc" id="L200">      .routing(routing));</span>
<span class="fc" id="L201">  }</span>

  /**
   * Delete all the documents matching the given search request. This method is blocking.
   * Index is refreshed, so docs are not searchable as soon as method is executed.
   * &lt;p&gt;
   * Note that the parameter indexType could be removed if progress logs are not needed.
   */
  public static IndexingResult delete(EsClient client, IndexType indexType, SearchRequest searchRequest) {
<span class="fc" id="L210">    BulkIndexer bulk = new BulkIndexer(client, indexType, Size.REGULAR);</span>
<span class="fc" id="L211">    bulk.start();</span>
<span class="fc" id="L212">    bulk.addDeletion(searchRequest);</span>
<span class="fc" id="L213">    return bulk.stop();</span>
  }

<span class="fc" id="L216">  private final class BulkProcessorListener implements Listener {</span>
    // a map containing per each request the associated profiler
<span class="fc" id="L218">    private final Map&lt;BulkRequest, Profiler&gt; profilerByRequest = new ConcurrentHashMap&lt;&gt;();</span>

    @Override
    public void beforeBulk(long executionId, BulkRequest request) {
<span class="fc" id="L222">      final Profiler profiler = Profiler.createIfTrace(EsClient.LOGGER);</span>
<span class="fc" id="L223">      profiler.start();</span>
<span class="fc" id="L224">      profilerByRequest.put(request, profiler);</span>
<span class="fc" id="L225">    }</span>

    @Override
    public void afterBulk(long executionId, BulkRequest request, BulkResponse response) {
<span class="fc" id="L229">      stopProfiler(request);</span>
<span class="fc" id="L230">      List&lt;DocId&gt; successDocIds = new ArrayList&lt;&gt;();</span>
<span class="fc bfc" id="L231" title="All 2 branches covered.">      for (BulkItemResponse item : response.getItems()) {</span>
<span class="fc bfc" id="L232" title="All 2 branches covered.">        if (item.isFailed()) {</span>
<span class="fc" id="L233">          LOGGER.error(&quot;index [{}], type [{}], id [{}], message [{}]&quot;, item.getIndex(), item.getType(), item.getId(), item.getFailureMessage());</span>
        } else {
<span class="fc" id="L235">          result.incrementSuccess();</span>
<span class="fc" id="L236">          successDocIds.add(new DocId(item.getIndex(), item.getType(), item.getId()));</span>
        }
      }
<span class="fc" id="L239">      indexingListener.onSuccess(successDocIds);</span>
<span class="fc" id="L240">    }</span>

    @Override
    public void afterBulk(long executionId, BulkRequest request, Throwable e) {
<span class="nc" id="L244">      LOGGER.error(&quot;Fail to execute bulk index request: {}&quot;, request, e);</span>
<span class="nc" id="L245">      stopProfiler(request);</span>
<span class="nc" id="L246">    }</span>

    private void stopProfiler(BulkRequest request) {
<span class="fc" id="L249">      final Profiler profiler = profilerByRequest.get(request);</span>
<span class="pc bpc" id="L250" title="1 of 4 branches missed.">      if (Objects.nonNull(profiler) &amp;&amp; profiler.isTraceEnabled()) {</span>
<span class="fc" id="L251">        profiler.stopTrace(toString(request));</span>
      }
<span class="fc" id="L253">      profilerByRequest.remove(request);</span>
<span class="fc" id="L254">    }</span>

    private String toString(BulkRequest bulkRequest) {
<span class="fc" id="L257">      StringBuilder message = new StringBuilder();</span>
<span class="fc" id="L258">      message.append(&quot;Bulk[&quot;);</span>
<span class="fc" id="L259">      Multiset&lt;BulkRequestKey&gt; groupedRequests = LinkedHashMultiset.create();</span>
<span class="fc bfc" id="L260" title="All 2 branches covered.">      for (int i = 0; i &lt; bulkRequest.requests().size(); i++) {</span>
<span class="fc" id="L261">        DocWriteRequest item = bulkRequest.requests().get(i);</span>
        String requestType;
<span class="fc bfc" id="L263" title="All 2 branches covered.">        if (item instanceof IndexRequest) {</span>
<span class="fc" id="L264">          requestType = &quot;index&quot;;</span>
<span class="pc bpc" id="L265" title="1 of 2 branches missed.">        } else if (item instanceof UpdateRequest) {</span>
<span class="nc" id="L266">          requestType = &quot;update&quot;;</span>
<span class="pc bpc" id="L267" title="1 of 2 branches missed.">        } else if (item instanceof DeleteRequest) {</span>
<span class="fc" id="L268">          requestType = &quot;delete&quot;;</span>
        } else {
          // Cannot happen, not allowed by BulkRequest's contract
<span class="nc" id="L271">          throw new IllegalStateException(&quot;Unsupported bulk request type: &quot; + item.getClass());</span>
        }
<span class="fc" id="L273">        groupedRequests.add(new BulkRequestKey(requestType, item.index(), item.type()));</span>
      }

<span class="fc" id="L276">      Set&lt;Multiset.Entry&lt;BulkRequestKey&gt;&gt; entrySet = groupedRequests.entrySet();</span>
<span class="fc" id="L277">      int size = entrySet.size();</span>
<span class="fc" id="L278">      int current = 0;</span>
<span class="fc bfc" id="L279" title="All 2 branches covered.">      for (Multiset.Entry&lt;BulkRequestKey&gt; requestEntry : entrySet) {</span>
<span class="fc" id="L280">        message.append(requestEntry.getCount()).append(&quot; &quot;).append(requestEntry.getElement().toString());</span>
<span class="fc" id="L281">        current++;</span>
<span class="fc bfc" id="L282" title="All 2 branches covered.">        if (current &lt; size) {</span>
<span class="fc" id="L283">          message.append(&quot;, &quot;);</span>
        }
<span class="fc" id="L285">      }</span>

<span class="fc" id="L287">      message.append(&quot;]&quot;);</span>
<span class="fc" id="L288">      return message.toString();</span>
    }
  }

  private static class BulkRequestKey {
    private String requestType;
    private String index;
    private String docType;

<span class="fc" id="L297">    private BulkRequestKey(String requestType, String index, String docType) {</span>
<span class="fc" id="L298">      this.requestType = requestType;</span>
<span class="fc" id="L299">      this.index = index;</span>
<span class="fc" id="L300">      this.docType = docType;</span>
<span class="fc" id="L301">    }</span>

    @Override
    public boolean equals(Object o) {
<span class="pc bpc" id="L305" title="1 of 2 branches missed.">      if (this == o) {</span>
<span class="nc" id="L306">        return true;</span>
      }
<span class="pc bpc" id="L308" title="2 of 4 branches missed.">      if (o == null || getClass() != o.getClass()) {</span>
<span class="nc" id="L309">        return false;</span>
      }
<span class="fc" id="L311">      BulkRequestKey that = (BulkRequestKey) o;</span>
<span class="pc bpc" id="L312" title="3 of 6 branches missed.">      return Objects.equals(docType, that.docType) &amp;&amp; Objects.equals(index, that.index) &amp;&amp; Objects.equals(requestType, that.requestType);</span>
    }

    @Override
    public int hashCode() {
<span class="fc" id="L317">      return Objects.hash(requestType, index, docType);</span>
    }

    @Override
    public String toString() {
<span class="fc" id="L322">      return String.format(&quot;%s requests on %s/%s&quot;, requestType, index, docType);</span>
    }
  }

<span class="fc" id="L326">  public enum Size {</span>
    /**
     * Use this size for a limited number of documents.
     */
<span class="fc" id="L330">    REGULAR {</span>
      @Override
      SizeHandler createHandler(Runtime2 runtime2) {
<span class="fc" id="L333">        return new SizeHandler();</span>
      }
    },

    /**
     * Large indexing is an heavy operation that populates an index generally from scratch. Replicas and
     * automatic refresh are disabled during bulk indexing and lucene segments are optimized at the end.
     * Use this size for initial indexing and if you expect unusual huge numbers of documents.
     */
<span class="fc" id="L342">    LARGE {</span>
      @Override
      SizeHandler createHandler(Runtime2 runtime2) {
<span class="fc" id="L345">        return new LargeSizeHandler(runtime2);</span>
      }
    };

    abstract SizeHandler createHandler(Runtime2 runtime2);
  }

  @VisibleForTesting
<span class="fc" id="L353">  static class Runtime2 {</span>
<span class="fc" id="L354">    private static final Runtime2 INSTANCE = new Runtime2();</span>

    int getCores() {
<span class="fc" id="L357">      return Runtime.getRuntime().availableProcessors();</span>
    }
  }

<span class="fc" id="L361">  static class SizeHandler {</span>
    /**
     * @see BulkProcessor.Builder#setConcurrentRequests(int)
     */
    int getConcurrentRequests() {
      // in the same thread by default
<span class="fc" id="L367">      return 0;</span>
    }

    void beforeStart(BulkIndexer bulkIndexer) {
      // nothing to do, to be overridden if needed
<span class="fc" id="L372">    }</span>

    void afterStop(BulkIndexer bulkIndexer) {
      // nothing to do, to be overridden if needed
<span class="fc" id="L376">    }</span>
  }

  static class LargeSizeHandler extends SizeHandler {

<span class="fc" id="L381">    private final Map&lt;String, Object&gt; initialSettings = new HashMap&lt;&gt;();</span>
    private final Runtime2 runtime2;
    private ProgressLogger progress;

<span class="fc" id="L385">    LargeSizeHandler(Runtime2 runtime2) {</span>
<span class="fc" id="L386">      this.runtime2 = runtime2;</span>
<span class="fc" id="L387">    }</span>

    @Override
    int getConcurrentRequests() {
      // see SONAR-8075
<span class="fc" id="L392">      int cores = runtime2.getCores();</span>
      // FIXME do not use DEFAULT_NUMBER_OF_SHARDS
<span class="fc" id="L394">      return Math.max(1, cores / DEFAULT_NUMBER_OF_SHARDS) - 1;</span>
    }

    @Override
    void beforeStart(BulkIndexer bulkIndexer) {
<span class="fc" id="L399">      String index = bulkIndexer.indexType.getMainType().getIndex().getName();</span>
<span class="fc" id="L400">      this.progress = new ProgressLogger(format(&quot;Progress[BulkIndexer[%s]]&quot;, index), bulkIndexer.result.total, LOGGER)</span>
<span class="fc" id="L401">        .setPluralLabel(&quot;requests&quot;);</span>
<span class="fc" id="L402">      this.progress.start();</span>
<span class="fc" id="L403">      Map&lt;String, Object&gt; temporarySettings = new HashMap&lt;&gt;();</span>

<span class="fc" id="L405">      GetSettingsResponse settingsResp = bulkIndexer.esClient.getSettings(new GetSettingsRequest());</span>

      // deactivate replicas
<span class="fc" id="L408">      int initialReplicas = Integer.parseInt(settingsResp.getSetting(index, IndexMetadata.SETTING_NUMBER_OF_REPLICAS));</span>
<span class="fc bfc" id="L409" title="All 2 branches covered.">      if (initialReplicas &gt; 0) {</span>
<span class="fc" id="L410">        initialSettings.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, initialReplicas);</span>
<span class="fc" id="L411">        temporarySettings.put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0);</span>
      }

      // deactivate periodical refresh
<span class="fc" id="L415">      String refreshInterval = settingsResp.getSetting(index, REFRESH_INTERVAL_SETTING);</span>
<span class="fc" id="L416">      initialSettings.put(REFRESH_INTERVAL_SETTING, refreshInterval);</span>
<span class="fc" id="L417">      temporarySettings.put(REFRESH_INTERVAL_SETTING, &quot;-1&quot;);</span>

<span class="fc" id="L419">      updateSettings(bulkIndexer, temporarySettings);</span>
<span class="fc" id="L420">    }</span>

    @Override
    void afterStop(BulkIndexer bulkIndexer) {
      // optimize lucene segments and revert index settings
      // Optimization must be done before re-applying replicas:
      // http://www.elasticsearch.org/blog/performance-considerations-elasticsearch-indexing/
<span class="fc" id="L427">      bulkIndexer.esClient.forcemerge(new ForceMergeRequest(bulkIndexer.indexType.getMainType().getIndex().getName()));</span>

<span class="fc" id="L429">      updateSettings(bulkIndexer, initialSettings);</span>
<span class="fc" id="L430">      this.progress.stop();</span>
<span class="fc" id="L431">    }</span>

    private static void updateSettings(BulkIndexer bulkIndexer, Map&lt;String, Object&gt; settings) {
<span class="fc" id="L434">      UpdateSettingsRequest req = new UpdateSettingsRequest(bulkIndexer.indexType.getMainType().getIndex().getName());</span>
<span class="fc" id="L435">      req.settings(settings);</span>
<span class="fc" id="L436">      bulkIndexer.esClient.putSettings(req);</span>
<span class="fc" id="L437">    }</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.11.202310140853</span></div></body></html>